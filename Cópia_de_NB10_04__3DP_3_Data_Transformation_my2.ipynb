{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de NB10_04__3DP_3_Data_Transformation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfinotti/DSWP/blob/master/C%C3%B3pia_de_NB10_04__3DP_3_Data_Transformation_my2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CgDLvphxfcX"
      },
      "source": [
        "<center><h1><b><i>3DP_3 - DATA TRANSFORMATION</i></b></h1></center>\n",
        "\n",
        "* **Objetivo**: Preparar os dados para o Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvW689ZBxbxH"
      },
      "source": [
        "# **AGENDA**:\n",
        "\n",
        "> Consulte **Table of contents**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiuYCCxGe8v"
      },
      "source": [
        "# **Melhorias da sessão**\n",
        "* Desenvolver a sessão sobe WOE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TdSY74U0XS9"
      },
      "source": [
        "___\n",
        "# **Referências**\n",
        "* [Why, How and When to Scale your Features](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)\n",
        "* [Demonstrating the different strategies of KBinsDiscretizer](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py);\n",
        "* [Why do we need feature scaling in Machine Learning and how to do it using SciKit Learn?](https://medium.com/@contactsunny/why-do-we-need-feature-scaling-in-machine-learning-and-how-to-do-it-using-scikit-learn-d8314206fe73)\n",
        "* [Importance of Feature Scaling](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py) --> Muito importante por demonstrar os efeitos e a importância de se transformar as colunas numéricas.\n",
        "* [Feature discretization](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_classification.html#sphx-glr-auto-examples-preprocessing-plot-discretization-classification-py) --> Mostra o impacto na acurácia dos modelos com e sem discretização. Ou seja, discretizar faz sentido!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DGifbWSmW3"
      },
      "source": [
        "___\n",
        "# **Machine Learning com Python (Scikit-Learn)**\n",
        "\n",
        "![Scikit-Learn](https://github.com/MathMachado/Materials/blob/master/scikit-learn-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg82Iouo_Qm2"
      },
      "source": [
        "# Porque dimensionar (Scale), padronizar (Standardize) e normalizar (Normalize) importa?\n",
        "* Porque muitos algoritmos de Machine Learning performam melhor ou convergem mais rápido quando os atributos/colunas/variáveis estão na mesma escala e possuem distribuição \"próxima\" da Normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-chlATnKSza"
      },
      "source": [
        "## Carregar as bibliotecas (genéricas) Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGVQB18-tM_"
      },
      "source": [
        "!pip install category_encoders\n",
        "!pip install update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmV5VlpfCAID"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJxrZckYxk6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import category_encoders as ce # library para aplicação do WOE - Weight Of Evidence para avaliar importância dos atributos\n",
        "\n",
        "# remove warnings to keep notebook clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyuWQM2NTMls"
      },
      "source": [
        "pd.options.display.float_format = '{:.2f}'.format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0fuDyI8_UPf"
      },
      "source": [
        "## Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oRWtarakgMY"
      },
      "source": [
        "### Dataframe gerado aleatoriamente - variáveis com distribuição Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXPXo3k0VDI"
      },
      "source": [
        "np.random.seed(20111974)\n",
        "\n",
        "i_N = 10000\n",
        "\n",
        "df_A1 = pd.DataFrame({\n",
        "    'coluna1': np.random.normal(0, 2, i_N), # Observem que a média das colunas são distintas\n",
        "    'coluna2': np.random.normal(50, 3, i_N),\n",
        "    'coluna3': np.random.normal(-5, 5, i_N),\n",
        "    'coluna4': np.random.normal(-10, 10, i_N)\n",
        "})\n",
        "\n",
        "df_A1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ST1JnoRZKm"
      },
      "source": [
        "**Dica**: Podemos usar outras distribuições (se quisermos), como a Exponential (mostrada abaixo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUqjo5QcQH99"
      },
      "source": [
        "np.random.seed(20111974)\n",
        "\n",
        "df_A2 = pd.DataFrame({\n",
        "    'coluna1': np.random.normal(0, 2, i_N),\n",
        "    'coluna2': np.random.normal(50, 3, i_N),\n",
        "    'coluna3': np.random.exponential(1, i_N), # coluna3 tem distribuição Exponential\n",
        "    'coluna4': np.random.normal(-10, 10, i_N)\n",
        "})\n",
        "\n",
        "df_A2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8MZNLbUkp8R"
      },
      "source": [
        "### Dataframe gerado aleatoriamente 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR-fDDujcTup"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "dados, classe = make_classification(n_samples = i_N, n_features = 4, n_informative = 3, n_redundant = 1, n_classes = 3)\n",
        "\n",
        "df_A3 = pd.DataFrame({'coluna1': dados[:,0],\n",
        "                                  'coluna2':dados[:,1],\n",
        "                                  'coluna3':dados[:,2],\n",
        "                                  'coluna4':dados[:,3]}) #, 'coluna5':classe})\n",
        "\n",
        "df_A3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq1cnpwLKvjS"
      },
      "source": [
        "df_A4 = pd.DataFrame({ \n",
        "    'coluna1': np.random.beta(5, 1, i_N) * 25, \n",
        "    'coluna2': np.random.exponential(10, i_N),\n",
        "    'coluna3': np.random.normal(10, 2, i_N),\n",
        "    'coluna4': np.random.normal(10, 10, i_N), \n",
        "})\n",
        "\n",
        "df_A4.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7sXQjvYRfhb"
      },
      "source": [
        "#### Extração de amostras para compararmos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjVHsnnHRkIo"
      },
      "source": [
        "df_A1_test = df_A1.sample(n = 100)\n",
        "df_A2_test = df_A2.sample(n = 100)\n",
        "df_A3_test = df_A3.sample(n = 100)\n",
        "df_A4_test = df_A4.sample(n = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0v0uXFRl-yG"
      },
      "source": [
        "___\n",
        "# **Transformações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkzTO0fdz93b"
      },
      "source": [
        "## (1) StandardScaler\n",
        "* StandardScaler é a transformação que centraliza os dados através da remoção da média (dos dados) e, na sequência, redimensiona (scale) através da divisão pelo desvio-padrão;\n",
        "* Após a transformação, os dados terão média zero e desvio-padrão 1;\n",
        "* Assume que os dados (as colunas a serem transformadas) são normalmente distribuidos ;\n",
        "* Se os dados não possuem distribuição Normal, então esta não é uma boa transformação a se aplicar.\n",
        "\n",
        "$$z_{i}= \\frac{x_{i}-mean(x)}{std(x)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1UOOWeQ0R_Y"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Lzx3xN6wpZ"
      },
      "source": [
        "df_A3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPq_7Vu2HCS"
      },
      "source": [
        "Histograma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYW9WwBC3hd_"
      },
      "source": [
        "plt.figure(figsize = (12, 8))\n",
        "plt.hist(df_A1['coluna3'], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
        "\n",
        "# Adiciona títulos e labels\n",
        "plt.title('Histograma da coluna3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ogcQvvT5zK"
      },
      "source": [
        "plt.figure(figsize = (12, 8))\n",
        "plt.hist(df_A2['coluna3'], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
        "\n",
        "# Adiciona títulos e labels\n",
        "plt.title('Histograma da coluna3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrgxkESc-Uaq"
      },
      "source": [
        "Considere o gráfico a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7dHTF1W-Xsn"
      },
      "source": [
        "df_A1.plot(kind = 'kde') # KDE (= kernel Density Estimate) ajuda-nos a visualizar a distribuição dos dados, análogo ao histograma."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMS72n14-hDO"
      },
      "source": [
        "Qual a interpretação para o gráfico acima?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izqGNcNILdaX"
      },
      "source": [
        "df_A1.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkAqlZg-p0v"
      },
      "source": [
        "A seguir, a transformação StandardScaler:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4u3T_BX-oc_"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voFQ4odSzzPZ"
      },
      "source": [
        "O ideal é termos um array com as preditoras, da seguinte forma:\n",
        "X = [coluna1, coluna2, ..., colunaN]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPa4-SCt-ynX"
      },
      "source": [
        "np.set_printoptions(precision = 3)\n",
        "\n",
        "A1_scale = StandardScaler().fit_transform(df_A1) # Combinação dos métodos fit() + transform()\n",
        "\n",
        "A1_scale_fit = StandardScaler().fit(df_A1) # Aplica o fit() separadamente\n",
        "A1_scale_transform = A1_scale_fit.transform(df_A1) # Aplica o transform() separadamente.\n",
        "A1_scale_fit_transform = StandardScaler().fit(df_A1).transform(df_A1) # Aplica fit().transform() encadeado\n",
        "\n",
        "A2_scale = StandardScaler().fit_transform(df_A2)\n",
        "\n",
        "A3_scale = StandardScaler().fit_transform(df_A3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioZ_IN3Z6d39"
      },
      "source": [
        "Observe abaixo que A1_scale = A1_scale_transform = A1_scale_fit_transform --> São arrays multidimensionais (do tipo NumPy)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4xQR4cu5D1J"
      },
      "source": [
        "A1_scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6GtN2KF4E_A"
      },
      "source": [
        "A1_scale_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q2bvSqb6T4g"
      },
      "source": [
        "A1_scale_fit_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIhaErnA46Fi"
      },
      "source": [
        "Transformando em dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhRvPze44JW"
      },
      "source": [
        "df_A1_scale = pd.DataFrame(A1_scale, columns = ['coluna1', 'coluna2', 'coluna3', 'coluna4'])\n",
        "df_A2_scale = pd.DataFrame(A2_scale, columns = ['coluna1', 'coluna2', 'coluna3', 'coluna4'])\n",
        "df_A3_scale = pd.DataFrame(A3_scale, columns = ['coluna1', 'coluna2', 'coluna3', 'coluna4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmQp8wDO_E88"
      },
      "source": [
        "Agora compare esse novo gráfico abaixo --> Vemos que os dados transformados tem distribuição Normal(0, 1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csfqRhDH2zUb"
      },
      "source": [
        "df_A1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-krh1pDg22RF"
      },
      "source": [
        "df_A1_scale.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fTPWsm_Hq3"
      },
      "source": [
        "df_A1_scale.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oN-829l3277"
      },
      "source": [
        "df_A2.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqh8L5BeUHT-"
      },
      "source": [
        "df_A2_scale.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvz6O1zk4XNE"
      },
      "source": [
        "df_A3.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffU-fQxCUSmm"
      },
      "source": [
        "df_A3_scale.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y24MOLL83w9j"
      },
      "source": [
        "### Exercício: Calcular a média e o desvio-padrão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Aa25gVlSdOi"
      },
      "source": [
        "df_A1.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZUiZImSmOE"
      },
      "source": [
        "df_A1_scale.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUQw5dpRwvA"
      },
      "source": [
        "#### Correlação das colunas\n",
        "* Observe que as correlações entre as variáveis não se alteram com as transformações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj1UerjORq9q"
      },
      "source": [
        "df_A1.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp6vPK0aR_p0"
      },
      "source": [
        "df_A1_scale.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fuURrao_M0c"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A9U7rs_RAT"
      },
      "source": [
        "## (2) MinMaxScaler\n",
        "* **Transformação muito popular e utilizada**.\n",
        "* Transforma os dados para o intervalo (0, 1);\n",
        "* Se StandardScaler não é aplicável, então essa transformação funciona bem.\n",
        "* Sensível aos outliers. Portanto, o ideal é que os outliers sejam tratados previamente.\n",
        "* Uma transformação similar à MinMaxScaler() é MaxAbsScaler() que redimensiona os dados no intervalo [-1, 1].\n",
        "\n",
        "$$z_{i}= \\frac{x_{i}-min(x)}{max(x)-min(x)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0HbeuP-AU_p"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgeLckzxAWaC"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_W9bTO2AbEg"
      },
      "source": [
        "df_A1.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJRFbUpBAg5J"
      },
      "source": [
        "A1_MinMaxScaler = MinMaxScaler().fit_transform(df_A1)\n",
        "df_A1_MinMaxScaler = pd.DataFrame(A1_MinMaxScaler,columns = ['coluna1', 'coluna2', 'coluna3', 'coluna4'])\n",
        "\n",
        "# Gráfico\n",
        "df_A1_MinMaxScaler.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g8GA4LTA40U"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z6D3vfnB9Nm"
      },
      "source": [
        "## (3) RobustScaler\n",
        "* Transformação ideal para dados com outliers.\n",
        "\n",
        "$$z_{i}= \\frac{x_{i}-Q_{1}(x)}{Q_{3}(x)-Q_{1}(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3oyuxLeCW1D"
      },
      "source": [
        "df_A1.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeDF7-w_CcBy"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoqSKijCf2v"
      },
      "source": [
        "A1_RobustScaler = RobustScaler().fit_transform(df_A1)\n",
        "df_A1_RobustScaler = pd.DataFrame(A1_RobustScaler, columns = ['coluna1', 'coluna2', 'coluna3', 'coluna4'])\n",
        "\n",
        "# Gráfico\n",
        "df_A1_RobustScaler.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YVMgt-WEFif"
      },
      "source": [
        "## Encoding Variáveis Categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHYvLc8T_jxQ"
      },
      "source": [
        "### Encoding Variáveis Ordinais\n",
        "* Exemplo: Variáveis com valores ordinais: baixo, médio ou alto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1BgGiGdSTcG"
      },
      "source": [
        "#### Gera um dataframe como exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdVahfJAEkuO"
      },
      "source": [
        "# Aqui vou usar a função randint - Retorna números inteiros aleatórios incluindo o número inferior e excluindo o superior.\n",
        "\n",
        "l_idade= [np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40),\n",
        "         np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40)]\n",
        "\n",
        "l_salario = ['baixo', 'medio', 'alto']\n",
        "l_salario2 = np.random.choice(l_salario, 10, p = [0.6, 0.3, 0.1])\n",
        "\n",
        "df_A4 = pd.DataFrame({\n",
        "    'idade': l_idade,\n",
        "    'salario': l_salario2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_15P2eUHSBY"
      },
      "source": [
        "df_A4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1g9pEuyHe2q"
      },
      "source": [
        "Neste exemplo, vamos redefinir a variável categórical ordinal 'Salario' da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwFuEa8HnMV"
      },
      "source": [
        "df_A4['salario_cat'] = df_A4['salario'].map({'baixo': 1, 'medio': 2, 'alto': 3})\n",
        "df_A4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlaIFiWIIPAl"
      },
      "source": [
        "### Encoding Variáveis Nominais\n",
        "* Exemplo: Variáveis com valores nominais: Sexo (Feminino, Masculino).\n",
        "\n",
        "* Use One-Hot Encoding ou pd.get.dummies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNoJQbgJRoY"
      },
      "source": [
        "Vamos utilizar o dataframe criado no passo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCoUWZOI7c0"
      },
      "source": [
        "df_A4['salario'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIEyBkaJeN8"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MwK4cUEKeK4"
      },
      "source": [
        "#### Aplicar LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6VXDsHJiII"
      },
      "source": [
        "le = LabelEncoder()\n",
        "df_A4['salario_le'] = le.fit_transform(df_A4['salario'])\n",
        "df_A4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY80x59J8Ham"
      },
      "source": [
        "df_A4['salario'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgv2Zz07Kqfj"
      },
      "source": [
        "#### Aplicar pd.get.dummies()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZRIEs6K5sP"
      },
      "source": [
        "dummies = pd.get_dummies(df_A4['salario'])\n",
        "df_A4 = pd.concat([df_A4, dummies], axis = 1)\n",
        "df_A4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY8GZ-HlNOgm"
      },
      "source": [
        "# **Wrap Up**\n",
        "* Use MinMaxScaler como transformação default, pois esta transformação não distorce os dados;\n",
        "* Use RobustScaler se seus dados/coluna/variável possui outliers e gostaríamos de reduzir o efeito/impacto destes outliers. Entretanto, o melhor tratamento é estudar os outliers cuidadosamente e tratá-los adequadamente;\n",
        "* Use StandardScaler se seus dados/colunas/variáveis possuem distribuição Normal (ou pelo menos se aproxima bem da distribuição Normal)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwh0alhdgrE3"
      },
      "source": [
        "___\n",
        "# **Exercícios**\n",
        "> Para cada um dos dataframes a seguir, aplique os seguintes steps:\n",
        "\n",
        "* Padronizar o nome das colunas\n",
        "    * Eliminar espaços entre os nomes das colunas;\n",
        "    * Eliminar caracteres especiais dos nomes das colunas;\n",
        "    * Renomear as colunas com lower() (ou upper());\n",
        "* Aplicar a trasformação StandardScaler e MinMaxScaler em cada uma das colunas do dataframe;\n",
        "* DataViz - Mostrar a distribuição das colunas para compararmos os resultados antes e depois das transformações.\n",
        "* As correlações das colunas mudam com as transformações?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSTKrd992LtI"
      },
      "source": [
        "## Exercício 1 - Iris --> **Resolvido**\n",
        "* [Aqui](https://en.wikipedia.org/wiki/Iris_flower_data_set) você obterá mais informações sobre o dataframe iris. Confira."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mThqvGGr2Vuk"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X= iris['data']\n",
        "y= iris['target']\n",
        "\n",
        "df_iris = pd.DataFrame(np.c_[X, y], columns= np.append(iris['feature_names'], ['target']))\n",
        "df_iris['target2'] = df_iris['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "df_iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR20V20gY0Wc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMjIyKDrY0LI"
      },
      "source": [
        "df_iris.columns.str.replace('\\s\\(cm\\)','', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hF1LzUbbMO7"
      },
      "source": [
        "df_iris.columns.str.replace(' ', '_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpqf5mF6b8jB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU5FaJhdYblP"
      },
      "source": [
        "df_iris.columns = [c.replace(' ', '_') for c in df_iris.columns]\n",
        "df_iris.columns = [c.replace('_(cm)', '') for c in df_iris.columns]\n",
        "df_iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9DPAakJZQHH"
      },
      "source": [
        "df_iris.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYYmVq68Y8bB"
      },
      "source": [
        "# Aplica a transformação Standard_Scaler:\n",
        "df_iris_StandartScaler = StandardScaler().fit_transform(df_iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
        "\n",
        "# Transformando em Dataframe:\n",
        "df_iris_StandartScaler = pd.DataFrame(df_iris_StandartScaler, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
        "\n",
        "# Gráfico\n",
        "df_iris_StandartScaler.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYq5rkd6dB-F"
      },
      "source": [
        "# Aplica a transformação:\n",
        "df_iris_MinMaxScaler = MinMaxScaler().fit_transform(df_iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
        "\n",
        "# Transformando em Dataframe:\n",
        "df_iris_MinMaxScaler = pd.DataFrame(df_iris_MinMaxScaler, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
        "\n",
        "# Gráfico\n",
        "df_iris_MinMaxScaler.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B36Cvi4ofpq2"
      },
      "source": [
        "# Correlações antes transformação\n",
        "df_iris.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPMbXPcfp0t"
      },
      "source": [
        "# apos StardartScaler\n",
        "df_iris_StandartScaler.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg2x989dfpgt"
      },
      "source": [
        "# apos MinMaxScaler\n",
        "df_iris_MinMaxScaler.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caFkC6oCmUKK"
      },
      "source": [
        "## Exercício 2 - Breast Cancer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOM-Z9zmf-f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X= cancer['data']\n",
        "y= cancer['target']\n",
        "\n",
        "df_A1_cancer = pd.DataFrame(np.c_[X, y], columns= np.append(cancer['feature_names'], ['target']))\n",
        "df_A1_cancer['target'] = df_A1_cancer['target'].map({0: 'malign', 1: 'benign'})\n",
        "df_A1_cancer.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Nk4i-reoiW"
      },
      "source": [
        "df_A1_cancer.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kEGIDuSdpyt"
      },
      "source": [
        "# padronizar colunas:\n",
        "df_A1_cancer.columns = [c.lower() for c in df_A1_cancer.columns] #lower case\n",
        "df_A1_cancer.columns = [c.replace(' ','_') for c in df_A1_cancer.columns] # troca espaco por underline\n",
        "df_A1_cancer.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yGpIeAJdqE_"
      },
      "source": [
        "dum = pd.get_dummies(df_A1_cancer['target'])\n",
        "df_A1_cancer = pd.concat([df_A1_cancer, dum], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo668tjkdpmf"
      },
      "source": [
        "df_A1_cancer.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeF9vkxaxGcV"
      },
      "source": [
        "df_A1_cancer.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cgw5CNb1RyW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNJ2WqOty20i"
      },
      "source": [
        "df_cancer_minmax = MinMaxScaler().fit_transform(df_A1_cancer[['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness','mean_compactness','mean_concavity','mean_concave_points',\n",
        "                                                        'mean_symmetry', 'mean_fractal_dimension','radius_error', 'texture_error', 'perimeter_error', 'area_error','smoothness_error', 'compactness_error',\n",
        "                                                        'concavity_error','concave_points_error', 'symmetry_error', 'fractal_dimension_error','worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
        "                                                        'worst_smoothness', 'worst_compactness', 'worst_concavity','worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension', 'benign', 'malign']])\n",
        "df_cancer_minmax = pd.DataFrame(df_cancer_minmax, columns = ['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness','mean_compactness','mean_concavity','mean_concave_points',\n",
        "                                                        'mean_symmetry', 'mean_fractal_dimension','radius_error', 'texture_error', 'perimeter_error', 'area_error','smoothness_error', 'compactness_error',\n",
        "                                                        'concavity_error','concave_points_error', 'symmetry_error', 'fractal_dimension_error','worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
        "                                                        'worst_smoothness', 'worst_compactness', 'worst_concavity','worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension', 'benign', 'malign'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcJnMC9IzVIR"
      },
      "source": [
        "df_cancer_minmax.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz6Ujy4LxEe8"
      },
      "source": [
        "[df_A1_cancer.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahnM5LlXxE_r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QQ3Kr4xEyc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df8u7rChxETW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qruqUDqnvMc"
      },
      "source": [
        "## Exercício 3 - Boston Housing Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxK8YXNnsam"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "X= boston['data']\n",
        "y= boston['target']\n",
        "\n",
        "df_A1_boston = pd.DataFrame(np.c_[X, y], columns= np.append(boston['feature_names'], ['target']))\n",
        "df_A1_boston.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzu0Dz33c8ds"
      },
      "source": [
        "## Exercícios 4 - Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ahBZmqc_-1"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X= diabetes['data']\n",
        "y= diabetes['target']\n",
        "\n",
        "df_A1_diabetes = pd.DataFrame(np.c_[X, y], columns= np.append(diabetes['feature_names'], ['target']))\n",
        "df_A1_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyunIr6oaWEl"
      },
      "source": [
        "## Exercícios 6 - 120 years of Olympic history: athletes and results\n",
        "* [120 years of Olympic history: athletes and results](https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results)\n",
        "    * Trate adequadamente as variáveis 'sex', 'season', 'team', 'city', 'sport' e 'medal';\n",
        "    * Aplique as transformações que acabamos de estudar nos campos/colunas numéricas 'height' e 'weight'. Cuidado com os Missing Values contidos nas variáveis!\n",
        "    * Verifique/avalie o impacto dos outliers nestas colunas.\n",
        "    * Neste caso, qual transformação é mais adequado diante dos outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5fDp1Ib_Dg8"
      },
      "source": [
        "# WOE - Weight Of Evidence\n",
        "* As vantagens da transformação WOE são\n",
        "    * Lida bem com NaN's;\n",
        "    * Lida bem com outliers;\n",
        "    * A transformação é baseada no valor logarítmico das distribuições.\n",
        "    * Usando a técnica de binning apropriada, pode estabelecer uma relação monotônica (aumentar ou diminuir) entre a variável dependente e independente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjGQC7mx_BYp"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/My Drive/datascience_files/athlete_events.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9HxbA-__CMI"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulnImlFU_CBK"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ICLGl272FvJ"
      },
      "source": [
        "df.columns = [c.lower() for c in df.columns] # converte nomes coluna para minusculas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EP_NXYZ2-qt"
      },
      "source": [
        "df['sex'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svATlL4r2-0k"
      },
      "source": [
        "df['season'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4cWqh4y2-e_"
      },
      "source": [
        "df['team'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3pwMJOT3PM2"
      },
      "source": [
        "df['sport'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpAGkENI3Pu8"
      },
      "source": [
        "df['medal'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t40vdDt03Peq"
      },
      "source": [
        "df['city'].unique()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58mYStdx4L_b"
      },
      "source": [
        "df['team'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UmKL7tfA5AF"
      },
      "source": [
        "# trate adequadamente as variáveis 'sex', 'season', 'team', 'city', 'sport' e 'medal'\n",
        "df['sex_'] = df['sex'].map({'M':0,'F':1}) # transforma em 0 e 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFovCujo1_-U"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VsY7KAJ4TJw"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzcrHshA2mNw"
      },
      "source": [
        "# usando label encoder para 'codificar' variáveis nominais\n",
        "le = LabelEncoder()\n",
        "df['season_'] = le.fit_transform(df['season'])\n",
        "df['team_'] = le.fit_transform(df['team'])\n",
        "df['city_'] = le.fit_transform(df['city'])\n",
        "df['sport_'] = le.fit_transform(df['sport'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7WHxMgK44RC"
      },
      "source": [
        "df['medal_'] = df['medal'].map({'Bronze':0, 'Silver':1, 'Gold':2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol2QDqHD5BiM"
      },
      "source": [
        "df[df.duplicated('name')].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSvbMQd52Z9"
      },
      "source": [
        "# Aplique as transformações que acabamos de estudar nos campos/colunas numéricas 'height' e 'weight'. Cuidado com os Missing Values contidos nas variáveis!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkBmnvwo6T0I"
      },
      "source": [
        "dfol = df[['name','id','team','sex','age','sport','height','weight']]\n",
        "dfol.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxA6mZFuUce6"
      },
      "source": [
        "dfol.groupby(by=['id','name']).agg({'height':['count','mean','max','min'],'weight':['count','mean','max','min']}).sort_values(by=('height','count'), ascending=False).head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzaC2ujOUdsm"
      },
      "source": [
        "# verificando se exsite variação nos valores de altura e peso para um mesmo atleta\n",
        "dfol.groupby('id').agg({'height':'std'}).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I-OhxeBUdPa"
      },
      "source": [
        "dfol.groupby('id')['height'].std().value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r37udrGPUc_a"
      },
      "source": [
        "dfol.groupby('id')['weight'].std().value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32DTYJmQenfA"
      },
      "source": [
        "# excluindo duplicados para fazer estatísticas com peso e altura\n",
        "dfol2 = dfol.drop_duplicates('id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH1P05fQenua"
      },
      "source": [
        "# verificando nova base\n",
        "dfol2.groupby(by=['id']).agg({'height':['count','mean','max','min'],'weight':['count','mean','max','min']}).sort_values(by=('height','count'), ascending=False).head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9GRB8erkj8f"
      },
      "source": [
        "# estatisticas antes de excluir IDs duplicados\n",
        "dfol[['age','height','weight']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pa3zLykkNm"
      },
      "source": [
        "# estatisticas após excluir IDs duplicados\n",
        "dfol2[['age','height','weight']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeysh06pkkEz"
      },
      "source": [
        "plt.figure(figsize = (8, 6))\n",
        "plt.hist(dfol['height'], color = 'blue', edgecolor = 'black', bins = int(180/5)) #hist antes de excluir dup\n",
        "plt.hist(dfol2['height'], color = 'red', edgecolor = 'black', bins = int(180/5)) #hist após excluir dup\n",
        "# Adiciona títulos e labels\n",
        "plt.title('Histograma da altura')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVWUSbPHkjxh"
      },
      "source": [
        "# Hist altura antes e apos duplicados com seaborn\n",
        "sns.histplot(data=dfol['height'], bins=36)\n",
        "sns.histplot(data=dfol2['height'], bins=36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz_caOqT6H_p"
      },
      "source": [
        "# Hist peso antes e apos duplicados com seaborn\n",
        "sns.histplot(data=dfol['weight'], bins=36)\n",
        "sns.histplot(data=dfol2['weight'], bins=36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyfe_a-j6anD"
      },
      "source": [
        "# grafico kde peso e altura após exclusao IDs duplicados\n",
        "dfol2[['height','weight']].plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-JvnYfD6vpz"
      },
      "source": [
        "# bibliotecas transformação sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AKiAVrm6ph-"
      },
      "source": [
        "# transformação StandardScaler\n",
        "dfol2_std = StandardScaler().fit_transform(dfol2[['height','weight']])\n",
        "dfol2_std = pd.DataFrame(dfol2_std, columns=['height','weight'])\n",
        "dfol2_std.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey0MdcbV7OsJ"
      },
      "source": [
        "# transformação minmax\n",
        "dfol2_minmax = MinMaxScaler().fit_transform(dfol2[['height','weight']])\n",
        "dfol2_minmax = pd.DataFrame(dfol2_minmax, columns=['height','weight'])\n",
        "dfol2_minmax.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3PlPjpm8y0l"
      },
      "source": [
        "# transformação RobustScaler\n",
        "dfol2_robust = RobustScaler().fit_transform(dfol2[['height','weight']])\n",
        "dfol2_robust = pd.DataFrame(dfol2_robust, columns=(['height','weight']))\n",
        "dfol2_robust.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_OM-Fr68ypI"
      },
      "source": [
        "# Transformação Power YeoJohnson\n",
        "power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "dfol2_ye = power.fit_transform(dfol2[['height', 'weight']])\n",
        "dfol2_ye = pd.DataFrame(dfol2_ye, columns=(['height', 'weight']))\n",
        "dfol2_ye.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4qyqjc3__fj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3pSDB0j8dEt"
      },
      "source": [
        "df_minmax.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lu9NZRa8giW"
      },
      "source": [
        "# outliers\n",
        "df[['height']].plot(kind='box')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTcn6iw683GQ"
      },
      "source": [
        "df[['weight']].plot(kind='box')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A31FvjjW9ds2"
      },
      "source": [
        "# aparentemente outliers são bem impactantes nestas 2 colunas. Talvez fosse o caso de usar a RobustScaler\n",
        "df_robust = RobustScaler().fit_transform(df[['height','weight']])\n",
        "df_robust = pd.DataFrame(df_robust, columns=(['height','weight']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbjZglzM-drI"
      },
      "source": [
        "df_robust.plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDF_YzI5-iug"
      },
      "source": [
        "df_robust.plot(kind='box')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgNrGlQl-nrl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}